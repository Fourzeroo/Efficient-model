{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прогнозирование временных рядов с использованием Informer\n",
    "\n",
    "Автоматический поиск архитектур (NAS) для задачи time-series forecasting с метрикой MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f\"Устройство: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_eth1 = \"https://raw.githubusercontent.com/zhouhaoyi/ETDataset/main/ETT-small/ETTh1.csv\"\n",
    "url_eth2 = \"https://raw.githubusercontent.com/zhouhaoyi/ETDataset/main/ETT-small/ETTh2.csv\"\n",
    "\n",
    "df_eth1 = pd.read_csv(url_eth1)\n",
    "df_eth2 = pd.read_csv(url_eth2)\n",
    "\n",
    "print(f\"ETTh1: {df_eth1.shape}\")\n",
    "print(f\"ETTh2: {df_eth2.shape}\")\n",
    "print(f\"Столбцы: {df_eth1.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 12 * 30 * 24\n",
    "val_size = 4 * 30 * 24\n",
    "\n",
    "train_df = df_eth1[:train_size]\n",
    "val_df = df_eth1[train_size:train_size + val_size]\n",
    "test_df = df_eth1[train_size + val_size:train_size + 2*val_size]\n",
    "\n",
    "feature_cols = [col for col in df_eth1.columns if col != 'date']\n",
    "target_col = 'OT'\n",
    "\n",
    "print(f\"Train: {train_df.shape}, Val: {val_df.shape}, Test: {test_df.shape}\")\n",
    "print(f\"Признаки: {feature_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Класс Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, seq_len, label_len, pred_len, features, target='OT', flag='train', scale=True, scaler=None):\n",
    "        self.seq_len = seq_len\n",
    "        self.label_len = label_len\n",
    "        self.pred_len = pred_len\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.flag = flag\n",
    "        \n",
    "        self.data_x = data[features].values\n",
    "        self.data_y = data[target].values\n",
    "        \n",
    "        if scale:\n",
    "            if scaler is None:\n",
    "                self.scaler = StandardScaler()\n",
    "                self.data_x = self.scaler.fit_transform(self.data_x)\n",
    "            else:\n",
    "                self.scaler = scaler\n",
    "                self.data_x = self.scaler.transform(self.data_x)\n",
    "        else:\n",
    "            self.scaler = None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        s_begin = index\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_end - self.label_len\n",
    "        r_end = r_begin + self.label_len + self.pred_len\n",
    "        \n",
    "        seq_x = self.data_x[s_begin:s_end]\n",
    "        seq_y = self.data_x[r_begin:r_end]\n",
    "        seq_x_mark = np.zeros((self.seq_len, 4))\n",
    "        seq_y_mark = np.zeros((self.label_len + self.pred_len, 4))\n",
    "        \n",
    "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Клонирование репозитория Informer2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('Informer2020'):\n",
    "    !git clone https://github.com/zhouhaoyi/Informer2020.git\n",
    "    print(\"Репозиторий клонирован\")\n",
    "else:\n",
    "    print(\"Репозиторий уже существует\")\n",
    "\n",
    "sys.path.append('Informer2020')\n",
    "from models.model import Informer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Функция создания модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(config):\n",
    "    model = Informer(\n",
    "        enc_in=config['enc_in'],\n",
    "        dec_in=config['dec_in'],\n",
    "        c_out=config['c_out'],\n",
    "        seq_len=config['seq_len'],\n",
    "        label_len=config['label_len'],\n",
    "        out_len=config['pred_len'],\n",
    "        factor=config.get('factor', 5),\n",
    "        d_model=config['d_model'],\n",
    "        n_heads=config['n_heads'],\n",
    "        e_layers=config['e_layers'],\n",
    "        d_layers=config['d_layers'],\n",
    "        d_ff=config['d_ff'],\n",
    "        dropout=config['dropout'],\n",
    "        attn='prob',\n",
    "        embed='timeF',\n",
    "        freq='h',\n",
    "        activation='gelu',\n",
    "        output_attention=False,\n",
    "        distil=True,\n",
    "        mix=True\n",
    "    ).to(device)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Цикл обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, label_len, pred_len):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_x, batch_y, batch_x_mark, batch_y_mark in dataloader:\n",
    "        batch_x = batch_x.float().to(device)\n",
    "        batch_y = batch_y.float().to(device)\n",
    "        batch_x_mark = batch_x_mark.float().to(device)\n",
    "        batch_y_mark = batch_y_mark.float().to(device)\n",
    "        \n",
    "        dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "        dec_inp = torch.cat([batch_y[:, :label_len, :], dec_inp], dim=1).float().to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "        \n",
    "        f_dim = -1\n",
    "        outputs = outputs[:, -pred_len:, f_dim:]\n",
    "        batch_y = batch_y[:, -pred_len:, f_dim:].to(device)\n",
    "        \n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def validate(model, dataloader, criterion, label_len, pred_len):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y, batch_x_mark, batch_y_mark in dataloader:\n",
    "            batch_x = batch_x.float().to(device)\n",
    "            batch_y = batch_y.float().to(device)\n",
    "            batch_x_mark = batch_x_mark.float().to(device)\n",
    "            batch_y_mark = batch_y_mark.float().to(device)\n",
    "            \n",
    "            dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "            dec_inp = torch.cat([batch_y[:, :label_len, :], dec_inp], dim=1).float().to(device)\n",
    "            \n",
    "            outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "            \n",
    "            f_dim = -1\n",
    "            outputs = outputs[:, -pred_len:, f_dim:]\n",
    "            batch_y = batch_y[:, -pred_len:, f_dim:].to(device)\n",
    "            \n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Optuna: Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    d_model = trial.suggest_categorical('d_model', [128, 256, 512])\n",
    "    \n",
    "    if d_model == 128:\n",
    "        n_heads = trial.suggest_categorical('n_heads', [4, 8])\n",
    "    elif d_model == 256:\n",
    "        n_heads = trial.suggest_categorical('n_heads', [4, 8])\n",
    "    else:  # 512\n",
    "        n_heads = trial.suggest_categorical('n_heads', [8, 16])\n",
    "    \n",
    "    config = {\n",
    "        'enc_in': len(feature_cols),\n",
    "        'dec_in': len(feature_cols),\n",
    "        'c_out': len(feature_cols),\n",
    "        'seq_len': trial.suggest_categorical('seq_len', [168, 336, 720]),\n",
    "        'label_len': trial.suggest_categorical('label_len', [24, 48, 72]),\n",
    "        'pred_len': 96,  \n",
    "        'd_model': d_model,\n",
    "        'n_heads': n_heads,\n",
    "        'e_layers': trial.suggest_int('e_layers', 2, 4),\n",
    "        'd_layers': trial.suggest_int('d_layers', 1, 2),\n",
    "        'd_ff': trial.suggest_categorical('d_ff', [d_model * 2, d_model * 4]),\n",
    "        'dropout': trial.suggest_float('dropout', 0.0, 0.5),\n",
    "        'factor': trial.suggest_int('factor', 3, 5),\n",
    "    }\n",
    "    \n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)\n",
    "    \n",
    "    train_dataset = TimeSeriesDataset(\n",
    "        train_df, config['seq_len'], config['label_len'], config['pred_len'], \n",
    "        feature_cols, target_col, 'train', scale=True\n",
    "    )\n",
    "    val_dataset = TimeSeriesDataset(\n",
    "        val_df, config['seq_len'], config['label_len'], config['pred_len'],\n",
    "        feature_cols, target_col, 'val', scale=True, scaler=train_dataset.scaler\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    model = create_model(config)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience = 5  \n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(20): \n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, config['label_len'], config['pred_len'])\n",
    "        val_loss = validate(model, val_loader, criterion, config['label_len'], config['pred_len'])\n",
    "        scheduler.step()\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            break\n",
    "        \n",
    "        trial.report(val_loss, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "    \n",
    "    return best_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = optuna.samplers.TPESampler(\n",
    "    seed=777, \n",
    "    n_startup_trials=10, \n",
    "    multivariate=True,  \n",
    ")\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner(\n",
    "    n_startup_trials=5,  \n",
    "    n_warmup_steps=5,  \n",
    "    interval_steps=1,  \n",
    ")\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    study_name='informer_nas_improved',\n",
    "    sampler=sampler,\n",
    "    pruner=pruner,\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Обучение финальной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config = {\n",
    "    'enc_in': len(feature_cols),\n",
    "    'dec_in': len(feature_cols),\n",
    "    'c_out': len(feature_cols),\n",
    "    'seq_len': study.best_params['seq_len'],\n",
    "    'label_len': study.best_params['label_len'],\n",
    "    'pred_len': 96,\n",
    "    'd_model': study.best_params['d_model'],\n",
    "    'n_heads': study.best_params['n_heads'],\n",
    "    'e_layers': study.best_params['e_layers'],\n",
    "    'd_layers': study.best_params['d_layers'],\n",
    "    'd_ff': study.best_params['d_ff'],\n",
    "    'dropout': study.best_params['dropout'],\n",
    "    'factor': study.best_params.get('factor', 5),  # factor из оптимизации\n",
    "}\n",
    "\n",
    "best_batch_size = study.best_params.get('batch_size', 32)\n",
    "best_lr = study.best_params.get('learning_rate', 1e-4)\n",
    "\n",
    "train_dataset = TimeSeriesDataset(\n",
    "    train_df, best_config['seq_len'], best_config['label_len'], best_config['pred_len'],\n",
    "    feature_cols, target_col, 'train', scale=True\n",
    ")\n",
    "val_dataset = TimeSeriesDataset(\n",
    "    val_df, best_config['seq_len'], best_config['label_len'], best_config['pred_len'],\n",
    "    feature_cols, target_col, 'val', scale=True, scaler=train_dataset.scaler\n",
    ")\n",
    "test_dataset = TimeSeriesDataset(\n",
    "    test_df, best_config['seq_len'], best_config['label_len'], best_config['pred_len'],\n",
    "    feature_cols, target_col, 'test', scale=True, scaler=train_dataset.scaler\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=best_batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=best_batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=best_batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "model = create_model(best_config)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=best_lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
    "\n",
    "print(f\"Параметров: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Batch size: {best_batch_size}\")\n",
    "print(f\"Learning rate: {best_lr:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, best_config['label_len'], best_config['pred_len'])\n",
    "    val_loss = validate(model, val_loader, criterion, best_config['label_len'], best_config['pred_len'])\n",
    "    scheduler.step()  \n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}, LR: {current_lr:.2e}\")\n",
    "\n",
    "print(f\"\\nОбучение завершено. Лучший Val Loss: {best_val_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Оценка на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "test_loss = validate(model, test_loader, criterion, best_config['label_len'], best_config['pred_len'])\n",
    "\n",
    "print(f\"Test MSE: {test_loss:.6f}\")\n",
    "print(f\"Test RMSE: {np.sqrt(test_loss):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(train_losses, label='Train Loss', linewidth=2)\n",
    "plt.plot(val_losses, label='Val Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Процесс обучения')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "label_len = best_config['label_len']\n",
    "pred_len = best_config['pred_len']\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y, batch_x_mark, batch_y_mark in test_loader:\n",
    "        batch_x = batch_x.float().to(device)\n",
    "        batch_y = batch_y.float().to(device)\n",
    "        batch_x_mark = batch_x_mark.float().to(device)\n",
    "        batch_y_mark = batch_y_mark.float().to(device)\n",
    "        \n",
    "        dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "        dec_inp = torch.cat([batch_y[:, :label_len, :], dec_inp], dim=1).float().to(device)\n",
    "        \n",
    "        outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "        \n",
    "        f_dim = -1\n",
    "        outputs = outputs[:, -pred_len:, f_dim:]\n",
    "        batch_y = batch_y[:, -pred_len:, f_dim:]\n",
    "        \n",
    "        predictions.append(outputs.cpu().numpy())\n",
    "        actuals.append(batch_y.cpu().numpy())\n",
    "\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "actuals = np.concatenate(actuals, axis=0)\n",
    "\n",
    "target_idx = feature_cols.index(target_col)\n",
    "pred_target = predictions[:, :, target_idx].flatten()[:500]\n",
    "actual_target = actuals[:, :, target_idx].flatten()[:500]\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(actual_target, label='Реальные значения', linewidth=2, color='green')\n",
    "plt.plot(pred_target, label='Прогноз', linewidth=2, color='red', alpha=0.8)\n",
    "plt.xlabel('Временной шаг')\n",
    "plt.ylabel(f'{target_col} (Temperature)')\n",
    "plt.title(f'Прогноз vs Реальные значения - {target_col}')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "mse = mean_squared_error(actual_target, pred_target)\n",
    "mae = mean_absolute_error(actual_target, pred_target)\n",
    "print(f\"\\nМетрики на тестовой выборке:\")\n",
    "print(f\"MSE: {mse:.6f}\")\n",
    "print(f\"RMSE: {np.sqrt(mse):.6f}\")\n",
    "print(f\"MAE: {mae:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. История Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_optimization_history(study)\n",
    "fig.show()\n",
    "\n",
    "fig = optuna.visualization.plot_param_importances(study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Project TimeSeries)",
   "language": "python",
   "name": "project-timeseries"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
