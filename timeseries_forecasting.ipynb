{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прогнозирование временных рядов с использованием Informer\n",
    "\n",
    "Автоматический поиск архитектур (NAS) для задачи time-series forecasting с метрикой MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom tqdm import tqdm\nimport optuna\nimport warnings\nwarnings.filterwarnings('ignore')\n\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelif torch.backends.mps.is_available():\n    device = torch.device('mps')\nelse:\n    device = torch.device('cpu')\nprint(f\"Устройство: {device}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_eth1 = \"https://raw.githubusercontent.com/zhouhaoyi/ETDataset/main/ETT-small/ETTh1.csv\"\n",
    "url_eth2 = \"https://raw.githubusercontent.com/zhouhaoyi/ETDataset/main/ETT-small/ETTh2.csv\"\n",
    "\n",
    "df_eth1 = pd.read_csv(url_eth1)\n",
    "df_eth2 = pd.read_csv(url_eth2)\n",
    "\n",
    "print(f\"ETTh1: {df_eth1.shape}\")\n",
    "print(f\"ETTh2: {df_eth2.shape}\")\n",
    "print(f\"Столбцы: {df_eth1.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 12 * 30 * 24\n",
    "val_size = 4 * 30 * 24\n",
    "\n",
    "train_df = df_eth1[:train_size]\n",
    "val_df = df_eth1[train_size:train_size + val_size]\n",
    "test_df = df_eth1[train_size + val_size:train_size + 2*val_size]\n",
    "\n",
    "feature_cols = [col for col in df_eth1.columns if col != 'date']\n",
    "target_col = 'OT'\n",
    "\n",
    "print(f\"Train: {train_df.shape}, Val: {val_df.shape}, Test: {test_df.shape}\")\n",
    "print(f\"Признаки: {feature_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Класс Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class TimeSeriesDataset(Dataset):\n    def __init__(self, data, seq_len, label_len, pred_len, features, target='OT', flag='train', scale=True, scaler=None):\n        self.seq_len = seq_len\n        self.label_len = label_len\n        self.pred_len = pred_len\n        self.features = features\n        self.target = target\n        self.flag = flag\n        \n        self.data_x = data[features].values\n        self.data_y = data[target].values\n        \n        if scale:\n            if scaler is None:\n                self.scaler = StandardScaler()\n                self.data_x = self.scaler.fit_transform(self.data_x)\n            else:\n                self.scaler = scaler\n                self.data_x = self.scaler.transform(self.data_x)\n        else:\n            self.scaler = None\n    \n    def __len__(self):\n        return len(self.data_x) - self.seq_len - self.pred_len + 1\n    \n    def __getitem__(self, index):\n        s_begin = index\n        s_end = s_begin + self.seq_len\n        r_begin = s_end - self.label_len\n        r_end = r_begin + self.label_len + self.pred_len\n        \n        seq_x = self.data_x[s_begin:s_end]\n        seq_y = self.data_x[r_begin:r_end]\n        # Для частоты 'h' (hourly) используем 4 признака временных меток\n        seq_x_mark = np.zeros((self.seq_len, 4))\n        seq_y_mark = np.zeros((self.label_len + self.pred_len, 4))\n        \n        return seq_x, seq_y, seq_x_mark, seq_y_mark\n\nprint(\"✓ Класс Dataset определен\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Клонирование репозитория Informer2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('Informer2020'):\n",
    "    !git clone https://github.com/zhouhaoyi/Informer2020.git\n",
    "    print(\"✓ Репозиторий клонирован\")\n",
    "else:\n",
    "    print(\"✓ Репозиторий уже существует\")\n",
    "\n",
    "sys.path.append('Informer2020')\n",
    "from models.model import Informer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Функция создания модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(config):\n",
    "    model = Informer(\n",
    "        enc_in=config['enc_in'],\n",
    "        dec_in=config['dec_in'],\n",
    "        c_out=config['c_out'],\n",
    "        seq_len=config['seq_len'],\n",
    "        label_len=config['label_len'],\n",
    "        out_len=config['pred_len'],\n",
    "        factor=config.get('factor', 5),\n",
    "        d_model=config['d_model'],\n",
    "        n_heads=config['n_heads'],\n",
    "        e_layers=config['e_layers'],\n",
    "        d_layers=config['d_layers'],\n",
    "        d_ff=config['d_ff'],\n",
    "        dropout=config['dropout'],\n",
    "        attn='prob',\n",
    "        embed='timeF',\n",
    "        freq='h',\n",
    "        activation='gelu',\n",
    "        output_attention=False,\n",
    "        distil=True,\n",
    "        mix=True\n",
    "    ).to(device)\n",
    "    return model\n",
    "\n",
    "print(\"✓ Функция создания модели определена\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Цикл обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def train_epoch(model, dataloader, criterion, optimizer, label_len, pred_len):\n    model.train()\n    total_loss = 0\n    \n    for batch_x, batch_y, batch_x_mark, batch_y_mark in dataloader:\n        batch_x = batch_x.float().to(device)\n        batch_y = batch_y.float().to(device)\n        batch_x_mark = batch_x_mark.float().to(device)\n        batch_y_mark = batch_y_mark.float().to(device)\n        \n        dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n        dec_inp = torch.cat([batch_y[:, :label_len, :], dec_inp], dim=1).float().to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n        \n        f_dim = -1\n        outputs = outputs[:, -pred_len:, f_dim:]\n        batch_y = batch_y[:, -pred_len:, f_dim:].to(device)\n        \n        loss = criterion(outputs, batch_y)\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n    \n    return total_loss / len(dataloader)\n\ndef validate(model, dataloader, criterion, label_len, pred_len):\n    model.eval()\n    total_loss = 0\n    \n    with torch.no_grad():\n        for batch_x, batch_y, batch_x_mark, batch_y_mark in dataloader:\n            batch_x = batch_x.float().to(device)\n            batch_y = batch_y.float().to(device)\n            batch_x_mark = batch_x_mark.float().to(device)\n            batch_y_mark = batch_y_mark.float().to(device)\n            \n            dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n            dec_inp = torch.cat([batch_y[:, :label_len, :], dec_inp], dim=1).float().to(device)\n            \n            outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n            \n            f_dim = -1\n            outputs = outputs[:, -pred_len:, f_dim:]\n            batch_y = batch_y[:, -pred_len:, f_dim:].to(device)\n            \n            loss = criterion(outputs, batch_y)\n            total_loss += loss.item()\n    \n    return total_loss / len(dataloader)\n\nprint(\"✓ Функции обучения определены\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Optuna: Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def objective(trial):\n    config = {\n        'enc_in': len(feature_cols),\n        'dec_in': len(feature_cols),\n        'c_out': len(feature_cols),\n        'seq_len': trial.suggest_categorical('seq_len', [96, 192, 336]),\n        'label_len': trial.suggest_categorical('label_len', [48, 96]),\n        'pred_len': 96,\n        'd_model': trial.suggest_categorical('d_model', [256, 512]),\n        'n_heads': trial.suggest_categorical('n_heads', [4, 8]),\n        'e_layers': trial.suggest_int('e_layers', 1, 3),\n        'd_layers': trial.suggest_int('d_layers', 1, 2),\n        'd_ff': trial.suggest_categorical('d_ff', [512, 1024, 2048]),\n        'dropout': trial.suggest_float('dropout', 0.0, 0.3),\n    }\n    \n    train_dataset = TimeSeriesDataset(\n        train_df, config['seq_len'], config['label_len'], config['pred_len'], \n        feature_cols, target_col, 'train', scale=True\n    )\n    val_dataset = TimeSeriesDataset(\n        val_df, config['seq_len'], config['label_len'], config['pred_len'],\n        feature_cols, target_col, 'val', scale=True, scaler=train_dataset.scaler\n    )\n    \n    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n    \n    model = create_model(config)\n    criterion = nn.MSELoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n    \n    best_val_loss = float('inf')\n    patience = 3\n    patience_counter = 0\n    \n    for epoch in range(10):\n        train_loss = train_epoch(model, train_loader, criterion, optimizer, config['label_len'], config['pred_len'])\n        val_loss = validate(model, val_loader, criterion, config['label_len'], config['pred_len'])\n        \n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            patience_counter = 0\n        else:\n            patience_counter += 1\n        \n        if patience_counter >= patience:\n            break\n        \n        trial.report(val_loss, epoch)\n        if trial.should_prune():\n            raise optuna.TrialPruned()\n    \n    return best_val_loss\n\nprint(\"✓ Objective функция для Optuna определена\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize', study_name='informer_nas')\n",
    "study.optimize(objective, n_trials=20, show_progress_bar=True)\n",
    "\n",
    "print(\"\\nЛучшие гиперпараметры:\")\n",
    "print(study.best_params)\n",
    "print(f\"\\nЛучший MSE: {study.best_value:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Обучение финальной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config = {\n",
    "    'enc_in': len(feature_cols),\n",
    "    'dec_in': len(feature_cols),\n",
    "    'c_out': len(feature_cols),\n",
    "    'seq_len': study.best_params['seq_len'],\n",
    "    'label_len': study.best_params['label_len'],\n",
    "    'pred_len': 96,\n",
    "    'd_model': study.best_params['d_model'],\n",
    "    'n_heads': study.best_params['n_heads'],\n",
    "    'e_layers': study.best_params['e_layers'],\n",
    "    'd_layers': study.best_params['d_layers'],\n",
    "    'd_ff': study.best_params['d_ff'],\n",
    "    'dropout': study.best_params['dropout'],\n",
    "}\n",
    "\n",
    "train_dataset = TimeSeriesDataset(\n",
    "    train_df, best_config['seq_len'], best_config['label_len'], best_config['pred_len'],\n",
    "    feature_cols, target_col, 'train', scale=True\n",
    ")\n",
    "val_dataset = TimeSeriesDataset(\n",
    "    val_df, best_config['seq_len'], best_config['label_len'], best_config['pred_len'],\n",
    "    feature_cols, target_col, 'val', scale=True, scaler=train_dataset.scaler\n",
    ")\n",
    "test_dataset = TimeSeriesDataset(\n",
    "    test_df, best_config['seq_len'], best_config['label_len'], best_config['pred_len'],\n",
    "    feature_cols, target_col, 'test', scale=True, scaler=train_dataset.scaler\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = create_model(best_config)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "print(f\"✓ Модель создана с лучшими параметрами\")\n",
    "print(f\"Параметров: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "epochs = 50\ntrain_losses = []\nval_losses = []\nbest_val_loss = float('inf')\n\nfor epoch in range(epochs):\n    train_loss = train_epoch(model, train_loader, criterion, optimizer, best_config['label_len'], best_config['pred_len'])\n    val_loss = validate(model, val_loader, criterion, best_config['label_len'], best_config['pred_len'])\n    \n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    \n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        torch.save(model.state_dict(), 'best_model.pth')\n    \n    if (epoch + 1) % 5 == 0:\n        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n\nprint(f\"\\n✓ Обучение завершено. Лучший Val Loss: {best_val_loss:.6f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Оценка на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "model.load_state_dict(torch.load('best_model.pth'))\ntest_loss = validate(model, test_loader, criterion, best_config['label_len'], best_config['pred_len'])\n\nprint(f\"Test MSE: {test_loss:.6f}\")\nprint(f\"Test RMSE: {np.sqrt(test_loss):.6f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(train_losses, label='Train Loss', linewidth=2)\n",
    "plt.plot(val_losses, label='Val Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Процесс обучения')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "model.eval()\npredictions = []\nactuals = []\n\nlabel_len = best_config['label_len']\npred_len = best_config['pred_len']\n\nwith torch.no_grad():\n    for batch_x, batch_y, batch_x_mark, batch_y_mark in test_loader:\n        batch_x = batch_x.float().to(device)\n        batch_y = batch_y.float().to(device)\n        batch_x_mark = batch_x_mark.float().to(device)\n        batch_y_mark = batch_y_mark.float().to(device)\n        \n        dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n        dec_inp = torch.cat([batch_y[:, :label_len, :], dec_inp], dim=1).float().to(device)\n        \n        outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n        \n        f_dim = -1\n        outputs = outputs[:, -pred_len:, f_dim:]\n        batch_y = batch_y[:, -pred_len:, f_dim:]\n        \n        predictions.append(outputs.cpu().numpy())\n        actuals.append(batch_y.cpu().numpy())\n\npredictions = np.concatenate(predictions, axis=0)\nactuals = np.concatenate(actuals, axis=0)\n\ntarget_idx = feature_cols.index(target_col)\npred_target = predictions[:, :, target_idx].flatten()[:500]\nactual_target = actuals[:, :, target_idx].flatten()[:500]\n\nplt.figure(figsize=(15, 6))\nplt.plot(actual_target, label='Реальные значения', linewidth=2, color='green')\nplt.plot(pred_target, label='Прогноз', linewidth=2, color='red', alpha=0.8)\nplt.xlabel('Временной шаг')\nplt.ylabel(f'{target_col} (Temperature)')\nplt.title(f'Прогноз vs Реальные значения - {target_col}')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nmse = mean_squared_error(actual_target, pred_target)\nmae = mean_absolute_error(actual_target, pred_target)\nprint(f\"\\nМетрики на тестовой выборке:\")\nprint(f\"MSE: {mse:.6f}\")\nprint(f\"RMSE: {np.sqrt(mse):.6f}\")\nprint(f\"MAE: {mae:.6f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. История Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_optimization_history(study)\n",
    "fig.show()\n",
    "\n",
    "fig = optuna.visualization.plot_param_importances(study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Project TimeSeries)",
   "language": "python",
   "name": "project-timeseries"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}